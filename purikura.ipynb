{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acb3bc3-b7b7-4f68-8453-a3a5b22dc075",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 画像のサイズを取得\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m original_height, original_width \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 2. 画像中の目・鼻・口を囲む矩形領域の抽出\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# カスケード分類器の準備\u001b[39;00m\n\u001b[0;32m     25\u001b[0m facecc_xml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaarcascades/haarcascade_frontalface_alt2.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input画像とOutput画像の名前を入力\n",
    "inimgname = \"src/retouch_full_l.jpg\"\n",
    "outimgname = \"beauty_\" + inimgname\n",
    "\n",
    "# 各パーツのリサイズ比を入力\n",
    "eyex = 1.1\n",
    "eyey = 1.3\n",
    "nosex = 0.8\n",
    "nosey = 1.1\n",
    "mouthx = 1.2\n",
    "mouthy = 1.1\n",
    "\n",
    "# 1. ファイルからの画像取得\n",
    "img = cv2.VideoCapture(0)\n",
    "\n",
    "# 画像のサイズを取得\n",
    "original_height, original_width = img.shape[:2]\n",
    "\n",
    "# 2. 画像中の目・鼻・口を囲む矩形領域の抽出\n",
    "\n",
    "# カスケード分類器の準備\n",
    "facecc_xml = \"haarcascades/haarcascade_frontalface_alt2.xml\"\n",
    "lefteyecc_xml = \"haarcascades/haarcascade_mcs_lefteye.xml\"\n",
    "righteyecc_xml = \"haarcascades/haarcascade_mcs_righteye.xml\"\n",
    "nosecc_xml = \"haarcascades/haarcascade_mcs_nose.xml\"\n",
    "mouthcc_xml = \"haarcascades/haarcascade_mcs_mouth.xml\"\n",
    "facecc = cv2.CascadeClassifier(facecc_xml)\n",
    "lefteyecc = cv2.CascadeClassifier(lefteyecc_xml)\n",
    "righteyecc = cv2.CascadeClassifier(righteyecc_xml)\n",
    "nosecc = cv2.CascadeClassifier(nosecc_xml)\n",
    "mouthcc = cv2.CascadeClassifier(mouthcc_xml)\n",
    "\n",
    "# 顔の検出\n",
    "facerects = facecc.detectMultiScale(img)  # rect<-rectangle\n",
    "\n",
    "# コピー画像を作成して、処理後の画像を保存する\n",
    "processed_img = img.copy()\n",
    "\n",
    "for facerect in facerects:\n",
    "    (x, y, w, h) = facerect\n",
    "    face = img[y:y + h, x:x + w]\n",
    "\n",
    "    # 左目の検出\n",
    "    leftupface = face[:int(len(face) / 2), int(len(face[0]) / 2):]\n",
    "    lefteyerects = lefteyecc.detectMultiScale(leftupface)\n",
    "    for lefteyerect in lefteyerects:\n",
    "        (lex, ley, lew, leh) = lefteyerect\n",
    "        lefteye = leftupface[ley:ley + leh, lex:lex + lew]\n",
    "        biglefteye = cv2.resize(lefteye, None, fx=eyex, fy=eyey)\n",
    "        starty = int(y + ley + len(lefteye) / 2 - len(biglefteye) / 2)\n",
    "        endy = int(y + ley + len(lefteye) / 2 + len(biglefteye) / 2)\n",
    "        startx = int(x + len(face[0]) / 2 + lex + len(lefteye[0]) / 2 - len(biglefteye[0]) / 2)\n",
    "        endx = int(x + len(face[0]) / 2 + lex + len(lefteye[0]) / 2 + len(biglefteye[0]) / 2)\n",
    "        processed_img[starty:endy, startx:endx] = biglefteye\n",
    "\n",
    "    # 右目の検出\n",
    "    rightupface = face[:int(len(face) / 2), :int(len(face[0]) / 2)]\n",
    "    righteyerects = righteyecc.detectMultiScale(rightupface)\n",
    "    for righteyerect in righteyerects:\n",
    "        (rex, rey, rew, reh) = righteyerect\n",
    "        righteye = rightupface[rey:rey + reh, rex:rex + rew]\n",
    "        bigrighteye = cv2.resize(righteye, None, fx=eyex, fy=eyey)\n",
    "        starty = int(y + rey + len(righteye) / 2 - len(bigrighteye) / 2)\n",
    "        endy = int(y + rey + len(righteye) / 2 + len(bigrighteye) / 2)\n",
    "        startx = int(x + rex + len(righteye[0]) / 2 - len(bigrighteye[0]) / 2)\n",
    "        endx = int(x + rex + len(righteye[0]) / 2 + len(bigrighteye[0]) / 2)\n",
    "        processed_img[starty:endy, startx:endx] = bigrighteye\n",
    "\n",
    "    # 鼻の検出\n",
    "    middleface = face[int(len(face) / 4):int(len(face) * 3 / 4), int(len(face) / 4):int(len(face) * 3 / 4)]\n",
    "    noserects = nosecc.detectMultiScale(middleface)\n",
    "    for noserect in noserects:\n",
    "        (nx, ny, nw, nh) = noserect\n",
    "        nose = middleface[ny:ny + nh, nx:nx + nw]\n",
    "        smallnose = cv2.resize(nose, None, fx=nosex, fy=nosey)\n",
    "        starty = int(len(face) / 4 + y + ny + len(nose) / 2 - len(smallnose) / 2)\n",
    "        endy = int(len(face) / 4 + y + ny + len(nose) / 2 + len(smallnose) / 2)\n",
    "        startx = int(len(face) / 4 + x + nx + len(nose[0]) / 2 - len(smallnose[0]) / 2)\n",
    "        endx = int(len(face) / 4 + x + nx + len(nose[0]) / 2 + len(smallnose[0]) / 2)\n",
    "        processed_img[starty:endy, startx:endx] = smallnose\n",
    "\n",
    "    # 口の検出\n",
    "    bottomface = face[int(len(face) / 2):, int(len(face) / 4):int(len(face) * 3 / 4)]\n",
    "    mouthrects = mouthcc.detectMultiScale(bottomface)\n",
    "    for mouthrect in mouthrects:\n",
    "        (mx, my, mw, mh) = mouthrect\n",
    "        mouth = bottomface[my:my + mh, mx:mx + mw]\n",
    "        bigmouth = cv2.resize(mouth, None, fx=mouthx, fy=mouthy)\n",
    "        starty = int(len(face) / 2 + y + my + len(mouth) / 2 - len(bigmouth) / 2)\n",
    "        endy = int(len(face) / 2 + y + my + len(mouth) / 2 + len(bigmouth) / 2)\n",
    "        startx = int(len(face) / 4 + x + mx + len(mouth[0]) / 2 - len(bigmouth[0]) / 2)\n",
    "        endx = int(len(face) / 4 + x + mx + len(mouth[0]) / 2 + len(bigmouth[0]) / 2)\n",
    "        processed_img[starty:endy, startx:endx] = bigmouth\n",
    "\n",
    "# 処理前と処理後の画像のサイズを調整（最適化）\n",
    "processed_img = cv2.resize(processed_img, (original_width, original_height))\n",
    "\n",
    "# 画像を水平に連結\n",
    "combined_image = np.hstack((img, processed_img))\n",
    "\n",
    "# 1つのウィンドウで連結された画像を表示\n",
    "cv2.imshow(\"Original and Processed Image\", combined_image)\n",
    "\n",
    "# キー入力待ち\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dbf0b-42cb-4d29-b9fb-cd9e43026f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
